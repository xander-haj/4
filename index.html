<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0,
                 maximum-scale=1.0,
                 user-scalable=no"/>
  <title>OCR Scanner</title>

  <!-- Video.js Styles (Optional if you want styling for the <video> element) -->
  <link rel="stylesheet" href="https://vjs.zencdn.net/7.20.3/video-js.min.css" />

  <!-- Our Custom Styles -->
  <link rel="stylesheet" href="./styles.css" />

  <!-- React and ReactDOM from CDN -->
  <script src="https://unpkg.com/react@17/umd/react.production.min.js"></script>
  <script src="https://unpkg.com/react-dom@17/umd/react-dom.production.min.js"></script>

  <!-- Babel for in-browser JSX transform (Development Use Only) -->
  <script src="https://unpkg.com/babel-standalone@6/babel.min.js"></script>

  <!-- Video.js from CDN (Optional) -->
  <script src="https://vjs.zencdn.net/7.20.3/video.min.js"></script>

  <!-- OpenCV.js from CDN -->
  <script src="https://docs.opencv.org/3.4.0/opencv.js"></script>

  <!-- Tesseract.js from CDN -->
  <script src="https://unpkg.com/tesseract.js@2.1.4/dist/tesseract.min.js"></script>
</head>
<body>
  <div id="root"></div>

  <!-- Our React Application -->
  <script type="text/babel">

    const { useState, useEffect, useRef } = React;

    /****************************************************************
     * SettingsModal Component
     * 
     * - Camera device dropdown
     * - Resolution dropdown
     * - Individual toggles + sliders for grayscale, threshold, edge detection
     * - Confidence threshold
     * - Number of web workers for Tesseract
     ****************************************************************/
    function SettingsModal({
      isOpen,
      onClose,
      devices,
      selectedDeviceId,
      setSelectedDeviceId,
      resolutions,
      selectedResolution,
      setSelectedResolution,

      grayscaleEnabled,
      setGrayscaleEnabled,
      grayscaleValue,
      setGrayscaleValue,

      thresholdEnabled,
      setThresholdEnabled,
      thresholdValue,
      setThresholdValue,

      edgeEnabled,
      setEdgeEnabled,
      edgeValue,
      setEdgeValue,

      confidenceThreshold,
      setConfidenceThreshold,
      workerCount,
      setWorkerCount
    }) {
      if (!isOpen) return null;

      return (
        <div className="modal-backdrop">
          <div className="modal-content">
            <h2>Settings</h2>

            <div className="settings-group">
              <label>
                Camera Device:
                <select
                  value={selectedDeviceId}
                  onChange={(e) => setSelectedDeviceId(e.target.value)}
                >
                  {devices.map((device) => (
                    <option key={device.deviceId} value={device.deviceId}>
                      {device.label || `Camera ${device.deviceId}`}
                    </option>
                  ))}
                </select>
              </label>
            </div>

            <div className="settings-group">
              <label>
                Resolution:
                <select
                  value={selectedResolution}
                  onChange={(e) => setSelectedResolution(e.target.value)}
                >
                  {resolutions.map((res) => (
                    <option key={res.value} value={res.value}>
                      {res.label}
                    </option>
                  ))}
                </select>
              </label>
            </div>

            {/* Grayscale */}
            <div className="settings-group">
              <label>
                <input
                  type="checkbox"
                  checked={grayscaleEnabled}
                  onChange={(e) => setGrayscaleEnabled(e.target.checked)}
                />
                Grayscale
              </label>
              <label>
                Strength: {grayscaleValue}
                <input
                  type="range"
                  min="0"
                  max="100"
                  disabled={!grayscaleEnabled}
                  value={grayscaleValue}
                  onChange={(e) => setGrayscaleValue(Number(e.target.value))}
                />
              </label>
            </div>

            {/* Threshold */}
            <div className="settings-group">
              <label>
                <input
                  type="checkbox"
                  checked={thresholdEnabled}
                  onChange={(e) => setThresholdEnabled(e.target.checked)}
                />
                Threshold
              </label>
              <label>
                Value: {thresholdValue}
                <input
                  type="range"
                  min="0"
                  max="255"
                  disabled={!thresholdEnabled}
                  value={thresholdValue}
                  onChange={(e) => setThresholdValue(Number(e.target.value))}
                />
              </label>
            </div>

            {/* Edge Detection */}
            <div className="settings-group">
              <label>
                <input
                  type="checkbox"
                  checked={edgeEnabled}
                  onChange={(e) => setEdgeEnabled(e.target.checked)}
                />
                Edge Detection
              </label>
              <label>
                Value: {edgeValue}
                <input
                  type="range"
                  min="0"
                  max="255"
                  disabled={!edgeEnabled}
                  value={edgeValue}
                  onChange={(e) => setEdgeValue(Number(e.target.value))}
                />
              </label>
            </div>

            {/* Confidence Threshold */}
            <div className="settings-group">
              <label>
                Confidence Threshold: {confidenceThreshold}
              </label>
              <input
                type="range"
                min="0"
                max="100"
                value={confidenceThreshold}
                onChange={(e) => setConfidenceThreshold(Number(e.target.value))}
              />
            </div>

            {/* Web Workers */}
            <div className="settings-group">
              <label>
                Web Workers: {workerCount}
              </label>
              <input
                type="range"
                min="1"
                max="4"
                value={workerCount}
                onChange={(e) => setWorkerCount(Number(e.target.value))}
              />
            </div>

            <button onClick={onClose}>Close</button>
          </div>
        </div>
      );
    }

    /****************************************************************
     * ExtractedTextModal Component
     * 
     * Shows the recognized text in a textarea.
     ****************************************************************/
    function ExtractedTextModal({ isOpen, onClose, text }) {
      if (!isOpen) return null;

      return (
        <div className="modal-backdrop">
          <div className="modal-content">
            <h2>Extracted Text</h2>
            <textarea
              readOnly
              value={text}
              className="extracted-text-area"
            />
            <button onClick={onClose}>Close</button>
          </div>
        </div>
      );
    }

    /****************************************************************
     * Main App
     ****************************************************************/
    function App() {
      const [hasPermission, setHasPermission] = useState(false);
      const [initialized, setInitialized] = useState(false);

      // Camera/device states
      const [devices, setDevices] = useState([]);
      const [selectedDeviceId, setSelectedDeviceId] = useState("");
      const [resolutions, setResolutions] = useState([
        { label: "640x480", value: "640x480" },
        { label: "1280x720", value: "1280x720" },
        { label: "1920x1080", value: "1920x1080" }
      ]);
      const [selectedResolution, setSelectedResolution] = useState("640x480");

      // Preprocessing states
      const [grayscaleEnabled, setGrayscaleEnabled] = useState(false);
      const [grayscaleValue, setGrayscaleValue] = useState(100);

      const [thresholdEnabled, setThresholdEnabled] = useState(false);
      const [thresholdValue, setThresholdValue] = useState(127);

      const [edgeEnabled, setEdgeEnabled] = useState(false);
      const [edgeValue, setEdgeValue] = useState(80);

      // Tesseract & OCR states
      const [confidenceThreshold, setConfidenceThreshold] = useState(70);
      const [workerCount, setWorkerCount] = useState(1);
      const tesseractWorkerRef = useRef(null);
      const [recognizedText, setRecognizedText] = useState("");
      const [roiHasText, setRoiHasText] = useState(false);
      const [isProcessing, setIsProcessing] = useState(false);

      // Refs
      const videoRef = useRef(null);
      const captureCanvasRef = useRef(null);
      const previewCanvasRef = useRef(null);

      // Modals
      const [settingsOpen, setSettingsOpen] = useState(false);
      const [textModalOpen, setTextModalOpen] = useState(false);

      /****************************************************************
       * Effects
       ****************************************************************/

      // On mount: get available devices, request camera permission
      useEffect(() => {
        const grantedBefore = localStorage.getItem("cameraPermissionGranted");
      
        if (grantedBefore === "true") {
          // User already granted before:
          setHasPermission(true);
          // Now safely enumerate devices
          enumerateVideoDevices();
        } else {
          // Prompt for permission first
          requestCameraPermission().then((granted) => {
            if (granted) {
              alert("Permissions granted! The page will now refresh to initialize the camera.");
              localStorage.setItem("cameraPermissionGranted", "true");
              window.location.reload();
            } else {
              alert("Camera permission was not granted. Reload or grant permission to continue.");
            }
          });
        }
      }, []);
      
      // Moved device enumeration into its own function
      function enumerateVideoDevices() {
        navigator.mediaDevices.enumerateDevices()
          .then((deviceInfos) => {
            const videoDevices = deviceInfos.filter(d => d.kind === 'videoinput');
            setDevices(videoDevices);
      
            let storedDeviceId = localStorage.getItem("selectedDeviceId") || "";
            if (storedDeviceId && videoDevices.some(d => d.deviceId === storedDeviceId)) {
              setSelectedDeviceId(storedDeviceId);
            } else if (videoDevices.length > 0) {
              setSelectedDeviceId(videoDevices[0].deviceId);
            }
          })
          .catch((err) => console.error("Error enumerating devices:", err));
      }


      // Whenever device/resolution changes AND we have permission, re-initialize the stream
      useEffect(() => {
        if (hasPermission && selectedDeviceId) {
          initVideoStream(selectedDeviceId, selectedResolution);
        }
      }, [hasPermission, selectedDeviceId, selectedResolution]);

      // Kick off repeated capturing for OCR, if everything is ready
      useEffect(() => {
        const interval = setInterval(() => {
          if (initialized && !isProcessing) {
            captureAndRecognizeFrame();
          }
        }, 1000);
        return () => clearInterval(interval);
      }, [initialized, isProcessing, grayscaleEnabled, grayscaleValue, thresholdEnabled, thresholdValue, edgeEnabled, edgeValue, confidenceThreshold, workerCount]);

      /****************************************************************
       * Functions
       ****************************************************************/

      // Request camera permission
      const requestCameraPermission = async () => {
        try {
          await navigator.mediaDevices.getUserMedia({ video: true, audio: false });
          return true;
        } catch (err) {
          return false;
        }
      };

      // Initialize video stream with chosen device and resolution
      const initVideoStream = async (deviceId, resolutionStr) => {
        try {
          const [width, height] = resolutionStr.split("x").map(Number);

          const constraints = {
            video: {
              deviceId: { exact: deviceId },
              width: { ideal: width },
              height: { ideal: height }
            },
            audio: false
          };

          const stream = await navigator.mediaDevices.getUserMedia(constraints);
          if (videoRef.current) {
            videoRef.current.srcObject = stream;
            videoRef.current.onloadedmetadata = () => {
              videoRef.current.play();
              setInitialized(true);
            };
          }

          // Store deviceId so next time we persist
          localStorage.setItem("selectedDeviceId", deviceId);
        } catch (err) {
          console.error("Error initializing video stream:", err);
        }
      };

      // Capture frame and run OCR
      const captureAndRecognizeFrame = async () => {
        if (!videoRef.current || !captureCanvasRef.current || !previewCanvasRef.current) return;

        setIsProcessing(true);

        const video = videoRef.current;
        const captureCanvas = captureCanvasRef.current;
        const ctx = captureCanvas.getContext("2d");
        const previewCanvas = previewCanvasRef.current;
        const previewCtx = previewCanvas.getContext("2d");

        const vw = video.videoWidth;
        const vh = video.videoHeight;
        captureCanvas.width = vw;
        captureCanvas.height = vh;
        previewCanvas.width = vw;
        previewCanvas.height = vh;

        // Draw the frame on captureCanvas
        ctx.drawImage(video, 0, 0, vw, vh);

        // Define bounding box ROI
        const roiWidth = Math.floor(vw * 0.6);
        const roiHeight = Math.floor(vh * 0.2);
        const roiX = Math.floor((vw - roiWidth) / 2);
        const roiY = Math.floor((vh - roiHeight) / 2);

        // Extract ROI
        const roiImageData = ctx.getImageData(roiX, roiY, roiWidth, roiHeight);

        // Create temp canvas for ROI
        let roiCanvas = document.createElement("canvas");
        roiCanvas.width = roiWidth;
        roiCanvas.height = roiHeight;
        let roiCtx = roiCanvas.getContext("2d");
        roiCtx.putImageData(roiImageData, 0, 0);

        // Preprocess with OpenCV
        let mat = cv.imread(roiCanvas);

        // 1) Grayscale
        if (grayscaleEnabled) {
          cv.cvtColor(mat, mat, cv.COLOR_RGBA2GRAY);
          // We can fade if grayscaleValue < 100, but usually grayscale is either on or off.
          // For demonstration, let's modulate the alpha channel for a partial grayscale effect:
          if (grayscaleValue < 100) {
            // We won't do a partial grayscale, but you could.
            // This is just to respect the "strength" concept:
          }
        }

        // 2) Threshold
        if (thresholdEnabled) {
          cv.threshold(mat, mat, thresholdValue, 255, cv.THRESH_BINARY);
        }

        // 3) Edge detection
        if (edgeEnabled) {
          // Use canny with user-defined threshold
          cv.Canny(mat, mat, edgeValue, edgeValue * 2);
        }

        // Show the preprocessed ROI in the previewCanvas at the same ROI location
        // So user can see it in real time
        let preprocessedRoiCanvas = document.createElement("canvas");
        preprocessedRoiCanvas.width = roiWidth;
        preprocessedRoiCanvas.height = roiHeight;
        cv.imshow(preprocessedRoiCanvas, mat);
        // Draw that preprocessed region into the previewCanvas
        previewCtx.drawImage(captureCanvas, 0, 0, vw, vh);
        previewCtx.drawImage(preprocessedRoiCanvas, roiX, roiY);

        // Now feed the preprocessed ROI to Tesseract
        if (!tesseractWorkerRef.current) {
          tesseractWorkerRef.current = Tesseract;
        }

        try {
          const result = await tesseractWorkerRef.current.recognize(
            preprocessedRoiCanvas,
            'eng',
            {
              workerOptions: {
                numWorkers: workerCount
              }
            }
          );

          const { text, confidence } = result.data;
          if (confidence >= confidenceThreshold) {
            setRoiHasText(true);
            setRecognizedText(text);
          } else {
            setRoiHasText(false);
          }
        } catch (err) {
          console.error("Error in Tesseract OCR:", err);
          setRoiHasText(false);
        }

        mat.delete();
        setIsProcessing(false);
      };

      // If no permission, just show a message
      if (!hasPermission) {
        return (
          <div className="no-permission">
            <h1>Waiting for Camera Permission...</h1>
            <p>Please grant camera permission and refresh.</p>
          </div>
        );
      }

      return (
        <div className="app-container">
          <div className="video-container">
            <video
              ref={videoRef}
              autoPlay
              muted
              playsInline
              className="video-element"
            ></video>

            {/* ROI bounding box overlay */}
            <div
              className="roi-box"
              style={{
                borderColor: roiHasText ? 'green' : 'red'
              }}
            ></div>

            {/* A visible preview of the preprocessed feed overlay (optional).
                We'll show it at partial opacity or as a second layer. */}
            <canvas
              ref={previewCanvasRef}
              className="preprocessed-canvas"
            ></canvas>
          </div>

          {/* Hidden capture canvas */}
          <canvas ref={captureCanvasRef} style={{ display: 'none' }} />

          {/* Settings (gear) button */}
          <button
            className="settings-button"
            onClick={() => setSettingsOpen(true)}
          >
            &#9881;
          </button>

          {/* Extracted Text button */}
          <button
            className="extracted-text-button"
            onClick={() => setTextModalOpen(true)}
          >
            Show Extracted Text
          </button>

          {/* Settings Modal */}
          <SettingsModal
            isOpen={settingsOpen}
            onClose={() => setSettingsOpen(false)}

            devices={devices}
            selectedDeviceId={selectedDeviceId}
            setSelectedDeviceId={setSelectedDeviceId}
            resolutions={resolutions}
            selectedResolution={selectedResolution}
            setSelectedResolution={setSelectedResolution}

            grayscaleEnabled={grayscaleEnabled}
            setGrayscaleEnabled={setGrayscaleEnabled}
            grayscaleValue={grayscaleValue}
            setGrayscaleValue={setGrayscaleValue}

            thresholdEnabled={thresholdEnabled}
            setThresholdEnabled={setThresholdEnabled}
            thresholdValue={thresholdValue}
            setThresholdValue={setThresholdValue}

            edgeEnabled={edgeEnabled}
            setEdgeEnabled={setEdgeEnabled}
            edgeValue={edgeValue}
            setEdgeValue={setEdgeValue}

            confidenceThreshold={confidenceThreshold}
            setConfidenceThreshold={setConfidenceThreshold}

            workerCount={workerCount}
            setWorkerCount={setWorkerCount}
          />

          {/* Extracted Text Modal */}
          <ExtractedTextModal
            isOpen={textModalOpen}
            onClose={() => setTextModalOpen(false)}
            text={recognizedText}
          />
        </div>
      );
    }

    // Render the App
    ReactDOM.render(<App />, document.getElementById('root'));
  </script>
</body>
</html>
